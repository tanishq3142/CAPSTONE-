{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Capstone Project: Polyp Segmentation (Kaggle Version)\n",
                "\n",
                "## Semi-Supervised Learning with Swin-UNet\n",
                "\n",
                "This notebook is adapted for the Kaggle environment. It implements a Semi-Supervised Learning (SSL) approach using a Swin-UNet architecture.\n",
                "\n",
                "**Key Features:**\n",
                "- **Data Source**: Expects `dataset1.zip` or extracted folder `CVC-ClinicDB-612` in `/kaggle/input`.\n",
                "- **Model**: Swin-UNet (Swin Transformer Encoder + U-Net Decoder).\n",
                "- **Training**: Iterative Pseudo-Labeling on unlabeled data.\n",
                "- **Outputs**: Saves models and plots to `/kaggle/working/capstone_output/`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Import Libraries ---\n",
                "import os\n",
                "import random\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm.notebook import tqdm\n",
                "import PIL.Image\n",
                "import cv2\n",
                "import glob\n",
                "import time\n",
                "import shutil\n",
                "import zipfile\n",
                "\n",
                "# --- PyTorch Imports ---\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
                "\n",
                "# --- Torchvision Imports ---\n",
                "import torchvision.transforms as T\n",
                "from torchvision.transforms.functional import to_pil_image, to_tensor, resize\n",
                "\n",
                "# --- Other Imports ---\n",
                "from sklearn.model_selection import train_test_split\n",
                "from transformers import SwinModel\n",
                "\n",
                "# --- Setup Seed for Reproducibility ---\n",
                "SEED = 42\n",
                "random.seed(SEED)\n",
                "np.random.seed(SEED)\n",
                "torch.manual_seed(SEED)\n",
                "if torch.cuda.is_available():\n",
                "    torch.cuda.manual_seed(SEED)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "    torch.backends.cudnn.benchmark = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 1. Kaggle Environment Setup & Data Handling ---\n",
                "\n",
                "# Define paths\n",
                "KAGGLE_INPUT_DIR = '/kaggle/input'\n",
                "KAGGLE_WORKING_DIR = '/kaggle/working'\n",
                "TEMP_DATA_DIR = '/kaggle/temp/dataset' # Temporary directory for extraction if needed\n",
                "\n",
                "# Search for the dataset\n",
                "dataset_root = None\n",
                "\n",
                "# Check if dataset is extracted in input\n",
                "possible_paths = [\n",
                "    os.path.join(KAGGLE_INPUT_DIR, 'dataset1', 'CVC-ClinicDB-612'),\n",
                "    os.path.join(KAGGLE_INPUT_DIR, 'dataset1'),\n",
                "    os.path.join(KAGGLE_INPUT_DIR, 'tanishqgupta3142/dataset1'),\n",
                "    # Add more likely paths if known\n",
                "]\n",
                "\n",
                "found_zip = False\n",
                "for p in possible_paths:\n",
                "    if os.path.exists(os.path.join(p, 'images')) and os.path.exists(os.path.join(p, 'Ground Truth')):\n",
                "        dataset_root = p\n",
                "        print(f\"Found extracted dataset at: {dataset_root}\")\n",
                "        break\n",
                "\n",
                "# If not found, look for zip and extract\n",
                "if dataset_root is None:\n",
                "    print(\"Dataset not immediately found in expected extraction paths. Searching for zip...\")\n",
                "    # Try to find zip file\n",
                "    zip_file = None\n",
                "    for root, dirs, files in os.walk(KAGGLE_INPUT_DIR):\n",
                "        for file in files:\n",
                "            if file.endswith('.zip'):\n",
                "                zip_file = os.path.join(root, file)\n",
                "                break\n",
                "        if zip_file:\n",
                "            break\n",
                "    \n",
                "    if zip_file:\n",
                "        print(f\"Found zip file: {zip_file}. Extracting to {TEMP_DATA_DIR}...\")\n",
                "        os.makedirs(TEMP_DATA_DIR, exist_ok=True)\n",
                "        with zipfile.ZipFile(zip_file, 'r') as zf:\n",
                "            zf.extractall(TEMP_DATA_DIR)\n",
                "        \n",
                "        # Locate 'images' inside temp dir\n",
                "        for root, dirs, files in os.walk(TEMP_DATA_DIR):\n",
                "            if 'images' in dirs and 'Ground Truth' in dirs:\n",
                "                dataset_root = root\n",
                "                break\n",
                "        print(f\"Dataset downloaded and extracted to: {dataset_root}\")\n",
                "    else:\n",
                "        # Fallback: Assume user will upload/add dataset named 'dataset1' properly\n",
                "        print(\"WARNING: Could not find dataset zip or folders. Assuming default structure relative to current directory or manual fix needed.\")\n",
                "        dataset_root = \"/kaggle/input/dataset1/CVC-ClinicDB-612\" # Best guess fallback\n",
                "\n",
                "DATA_ROOT = dataset_root\n",
                "IMAGE_DIR = os.path.join(DATA_ROOT, \"images\")\n",
                "MASK_DIR = os.path.join(DATA_ROOT, \"Ground Truth\")\n",
                "\n",
                "# --- 2. Output Configuration ---\n",
                "# Define output paths for saving models and plots\n",
                "OUTPUT_ROOT = os.path.join(KAGGLE_WORKING_DIR, 'capstone_output')\n",
                "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
                "\n",
                "print(f\"Data Source: {DATA_ROOT}\")\n",
                "print(f\"Output Directory: {OUTPUT_ROOT}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 3. Core Experiment Parameters ---\n",
                "TRAINING_SIZE = 25       # Options: 25, 50, 75, 100 (SSL) or 490 (Fully Supervised)\n",
                "NUM_EPOCHS = 20\n",
                "START_EPOCH = 0          # Set to > 0 to resume training from 'latest_model.pth'\n",
                "ITERATIONS_PER_EPOCH = 20 # Number of training batches per epoch (for SSL)\n",
                "PSEUDO_LABEL_INTERVAL = 5  # Iterations to wait before pseudo-labeling (for SSL)\n",
                "CONFIDENCE_THRESHOLD = 0.79 # Confidence score to accept a pseudo-label (for SSL)\n",
                "\n",
                "BATCH_SIZE = 16\n",
                "LEARNING_RATE = 1e-4\n",
                "IMAGE_SIZE = 224\n",
                "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "\n",
                "# Specific Run Paths\n",
                "RUN_PATH = os.path.join(OUTPUT_ROOT, f'{TRAINING_SIZE}')\n",
                "PLOT_PATH = os.path.join(RUN_PATH, 'plots')\n",
                "LATEST_MODEL_PATH = os.path.join(RUN_PATH, 'latest_model.pth')\n",
                "BEST_MODEL_PATH = os.path.join(RUN_PATH, 'best_model.pth')\n",
                "\n",
                "os.makedirs(RUN_PATH, exist_ok=True)\n",
                "os.makedirs(PLOT_PATH, exist_ok=True)\n",
                "\n",
                "print(f\"--- Experiment Configuration ---\")\n",
                "print(f\"Training Scenario: {'Semi-Supervised' if TRAINING_SIZE < 490 else 'Fully Supervised'}\")\n",
                "print(f\"Training Size: {TRAINING_SIZE}\")\n",
                "print(f\"Device: {DEVICE}\")\n",
                "print(f\"Run Path: {RUN_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 4. Model Architecture (Swin-UNet) ---\n",
                "\n",
                "class SwinUNet(nn.Module):\n",
                "    def __init__(self, num_classes=1):\n",
                "        super(SwinUNet, self).__init__()\n",
                "        # Encoder: Pre-trained Swin Transformer\n",
                "        self.swin = SwinModel.from_pretrained(\n",
                "            \"microsoft/swin-base-patch4-window7-224\",\n",
                "            output_hidden_states=True,\n",
                "        )\n",
                "\n",
                "        # Freeze some early layers of the encoder\n",
                "        for name, param in self.swin.named_parameters():\n",
                "            if \"layers.0\" in name or \"layers.1\" in name or \"embed\" in name:\n",
                "                 param.requires_grad = False\n",
                "\n",
                "        # --- Decoder ---\n",
                "        self.decoder4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2, padding=0)\n",
                "        self.conv4 = nn.Sequential(nn.Conv2d(1024, 512, 3, padding=1), nn.ReLU())\n",
                "\n",
                "        self.decoder3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2, padding=0)\n",
                "        self.conv3 = nn.Sequential(nn.Conv2d(512, 256, 3, padding=1), nn.ReLU())\n",
                "\n",
                "        self.decoder2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2, padding=0)\n",
                "        self.conv2 = nn.Sequential(nn.Conv2d(256, 128, 3, padding=1), nn.ReLU())\n",
                "\n",
                "        # Final upsampling layers\n",
                "        self.final_upsample = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True) \n",
                "        self.final_conv = nn.Sequential(\n",
                "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
                "            nn.ReLU(inplace=True),\n",
                "            nn.Conv2d(64, num_classes, kernel_size=1)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        hidden_states = self.swin(x).hidden_states\n",
                "\n",
                "        # Stage 1: (B, 56*56, 128) -> (B, 128, 56, 56)\n",
                "        B, L1, C1 = hidden_states[0].shape\n",
                "        H1 = W1 = int(L1**0.5)\n",
                "        s1 = hidden_states[0].reshape(B, H1, W1, C1).permute(0, 3, 1, 2)\n",
                "\n",
                "        # Stage 2: (B, 28*28, 256) -> (B, 256, 28, 28)\n",
                "        B, L2, C2 = hidden_states[1].shape\n",
                "        H2 = W2 = int(L2**0.5)\n",
                "        s2 = hidden_states[1].reshape(B, H2, W2, C2).permute(0, 3, 1, 2)\n",
                "\n",
                "        # Stage 3: (B, 14*14, 512) -> (B, 512, 14, 14)\n",
                "        B, L3, C3 = hidden_states[2].shape\n",
                "        H3 = W3 = int(L3**0.5)\n",
                "        s3 = hidden_states[2].reshape(B, H3, W3, C3).permute(0, 3, 1, 2)\n",
                "\n",
                "        # Stage 4: (B, 7*7, 1024) -> (B, 1024, 7, 7)\n",
                "        B, L4, C4 = hidden_states[3].shape\n",
                "        H4 = W4 = int(L4**0.5)\n",
                "        s4 = hidden_states[3].reshape(B, H4, W4, C4).permute(0, 3, 1, 2)\n",
                "\n",
                "        # --- Decoder Path with Skip Connections ---\n",
                "        # Upsample d4 to match s3 (7x7 -> 14x14)\n",
                "        d4 = self.decoder4(s4)\n",
                "        d4 = torch.cat([d4, s3], dim=1)\n",
                "        d4 = self.conv4(d4)\n",
                "\n",
                "        # Upsample d3 to match s2 (14x14 -> 28x28)\n",
                "        d3 = self.decoder3(d4)\n",
                "        d3 = torch.cat([d3, s2], dim=1)\n",
                "        d3 = self.conv3(d3)\n",
                "\n",
                "        # Upsample d2 to match s1 (28x28 -> 56x56)\n",
                "        d2 = self.decoder2(d3)\n",
                "        d2 = torch.cat([d2, s1], dim=1)\n",
                "        d2 = self.conv2(d2)\n",
                "\n",
                "        # Final upsampling to 224x224\n",
                "        out = self.final_upsample(d2)\n",
                "        out = self.final_conv(out)\n",
                "\n",
                "        return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 5. Loss & Metrics ---\n",
                "\n",
                "class DiceLoss(nn.Module):\n",
                "    def __init__(self, smooth=1.0):\n",
                "        super(DiceLoss, self).__init__()\n",
                "        self.smooth = smooth\n",
                "\n",
                "    def forward(self, logits, targets):\n",
                "        probs = torch.sigmoid(logits)\n",
                "        probs_flat = probs.view(-1)\n",
                "        targets_flat = targets.view(-1)\n",
                "        intersection = (probs_flat * targets_flat).sum()\n",
                "        dice = (2. * intersection + self.smooth) / (probs_flat.sum() + targets_flat.sum() + self.smooth)\n",
                "        return 1 - dice\n",
                "\n",
                "def combined_loss(logits, targets):\n",
                "    bce = nn.BCEWithLogitsLoss()\n",
                "    dice = DiceLoss()\n",
                "    return bce(logits, targets) + dice(logits, targets)\n",
                "\n",
                "def calculate_metrics(logits, targets, threshold=0.5, epsilon=1e-6):\n",
                "    probs = torch.sigmoid(logits)\n",
                "    preds = (probs > threshold).float()\n",
                "\n",
                "    preds_flat = preds.view(-1)\n",
                "    targets_flat = targets.view(-1)\n",
                "\n",
                "    intersection = (preds_flat * targets_flat).sum()\n",
                "\n",
                "    dice_score = (2. * intersection) / (preds_flat.sum() + targets_flat.sum() + epsilon)\n",
                "    \n",
                "    union = preds_flat.sum() + targets_flat.sum() - intersection\n",
                "    iou_score = (intersection) / (union + epsilon)\n",
                "\n",
                "    return iou_score.item(), dice_score.item()\n",
                "\n",
                "def get_confidence_score(probs, pred_mask, epsilon=1e-6):\n",
                "    confidence = (probs * pred_mask).sum() / (pred_mask.sum() + epsilon)\n",
                "    return confidence.item()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 6. Dataset Class ---\n",
                "\n",
                "class PolypDataset(Dataset):\n",
                "    def __init__(self, image_filenames, image_dir, mask_dir, transform=None, pseudo_masks=None):\n",
                "        self.image_filenames = image_filenames\n",
                "        self.image_dir = image_dir\n",
                "        self.mask_dir = mask_dir\n",
                "        self.transform = transform\n",
                "        self.pseudo_masks = pseudo_masks if pseudo_masks is not None else {}\n",
                "\n",
                "        self.image_transform = T.Compose([\n",
                "            T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
                "            T.ToTensor(),\n",
                "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "        ])\n",
                "        self.mask_transform = T.Compose([\n",
                "            T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
                "            T.ToTensor(),\n",
                "        ])\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.image_filenames)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        filename = self.image_filenames[idx]\n",
                "        img_path = os.path.join(self.image_dir, filename)\n",
                "        image = PIL.Image.open(img_path).convert(\"RGB\")\n",
                "\n",
                "        if filename in self.pseudo_masks:\n",
                "            mask_np = self.pseudo_masks[filename]\n",
                "            mask = PIL.Image.fromarray((mask_np * 255).astype(np.uint8))\n",
                "        else:\n",
                "            mask_path = os.path.join(self.mask_dir, filename)\n",
                "            mask = PIL.Image.open(mask_path).convert(\"L\")\n",
                "\n",
                "        image = self.image_transform(image)\n",
                "        mask = self.mask_transform(mask)\n",
                "        mask = (mask > 0.5).float()\n",
                "\n",
                "        return image, mask, filename"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 7. Data Splitting & Learners ---\n",
                "\n",
                "all_filenames = sorted([f for f in os.listdir(IMAGE_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
                "print(f\"Found {len(all_filenames)} total images\")\n",
                "\n",
                "# Split main pool and fixed validation pool\n",
                "train_pool_files, val_pool_files = train_test_split(\n",
                "    all_filenames,\n",
                "    test_size=0.15,\n",
                "    random_state=SEED\n",
                ")\n",
                "\n",
                "print(f\"Training Pool: {len(train_pool_files)}\")\n",
                "print(f\"Validation Pool: {len(val_pool_files)}\")\n",
                "\n",
                "val_dataset = PolypDataset(\n",
                "    image_filenames=val_pool_files,\n",
                "    image_dir=IMAGE_DIR,\n",
                "    mask_dir=MASK_DIR\n",
                ")\n",
                "val_loader = DataLoader(\n",
                "    val_dataset,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    shuffle=False,\n",
                "    num_workers=2\n",
                ")\n",
                "\n",
                "# Define Pools\n",
                "if TRAINING_SIZE == 490: # Fully supervised\n",
                "    labeled_pool_files = train_pool_files\n",
                "    unlabeled_pool_files = []\n",
                "    train_loader = DataLoader(\n",
                "        PolypDataset(labeled_pool_files, IMAGE_DIR, MASK_DIR),\n",
                "        batch_size=BATCH_SIZE,\n",
                "        shuffle=True,\n",
                "        num_workers=2\n",
                "    )\n",
                "else: # Semi-Supervised\n",
                "    labeled_pool_files = train_pool_files[:TRAINING_SIZE]\n",
                "    unlabeled_pool_files = train_pool_files[TRAINING_SIZE:]\n",
                "    # Train loader will be re-created in the loop\n",
                "    print(f\"Initial Labeled: {len(labeled_pool_files)}, Unlabeled: {len(unlabeled_pool_files)}\")\n",
                "\n",
                "pseudo_masks = {}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 8. Visualization Utilities ---\n",
                "\n",
                "def save_loss_metric_plots(train_losses, val_losses, train_metrics, val_metrics, current_epoch, save_path):\n",
                "    \"\"\"Saves plots for loss and metrics vs. epoch.\"\"\"\n",
                "    epochs = range(1, current_epoch + 1)\n",
                "\n",
                "    # --- Loss Plot ---\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    plt.plot(epochs, train_losses, 'b-o', label='Training Loss')\n",
                "    plt.plot(epochs, val_losses, 'r-o', label='Validation Loss')\n",
                "    plt.title(f'Training vs. Validation Loss (Epoch {current_epoch})')\n",
                "    plt.xlabel('Epochs')\n",
                "    plt.ylabel('Loss')\n",
                "    plt.legend()\n",
                "    plt.grid(True)\n",
                "    plt.savefig(os.path.join(save_path, f'loss_curve_epoch_{current_epoch}.png'))\n",
                "    plt.close()\n",
                "\n",
                "    # --- Metric (mIoU) Plot ---\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    plt.plot(epochs, train_metrics, 'b-o', label='Training mIoU')\n",
                "    plt.plot(epochs, val_metrics, 'r-o', label='Validation mIoU')\n",
                "    plt.title(f'Training vs. Validation mIoU (Epoch {current_epoch})')\n",
                "    plt.xlabel('Epochs')\n",
                "    plt.ylabel('mIoU')\n",
                "    plt.legend()\n",
                "    plt.grid(True)\n",
                "    plt.savefig(os.path.join(save_path, f'miou_curve_epoch_{current_epoch}.png'))\n",
                "    plt.close()\n",
                "\n",
                "def save_data_growth_plot(pool_sizes, current_epoch, save_path):\n",
                "    \"\"\"Saves a bar chart of the labeled pool size growth.\"\"\"\n",
                "    if not pool_sizes:\n",
                "        return\n",
                "\n",
                "    epochs = range(1, current_epoch + 1)\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    plt.bar(epochs, pool_sizes, color='green')\n",
                "    plt.title(f'Labeled Pool Size Growth (Epoch {current_epoch})')\n",
                "    plt.xlabel('Epochs')\n",
                "    plt.ylabel('Number of Labeled Samples')\n",
                "    plt.xticks(epochs)\n",
                "    plt.grid(axis='y', linestyle='--')\n",
                "    plt.savefig(os.path.join(save_path, f'data_growth_epoch_{current_epoch}.png'))\n",
                "    plt.close()\n",
                "\n",
                "def save_new_labels_plot(new_labels, current_epoch, save_path):\n",
                "    \"\"\"Saves a bar chart of the new pseudo-labels added per epoch.\"\"\"\n",
                "    if not new_labels:\n",
                "        return\n",
                "\n",
                "    epochs = range(1, current_epoch + 1)\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    plt.bar(epochs, new_labels, color='dodgerblue')\n",
                "    plt.title(f'New Pseudo-Labels Added Per Epoch (Epoch {current_epoch})')\n",
                "    plt.xlabel('Epochs')\n",
                "    plt.ylabel('Number of New Samples Added')\n",
                "    plt.xticks(epochs)\n",
                "    plt.grid(axis='y', linestyle='--')\n",
                "    plt.savefig(os.path.join(save_path, f'new_labels_per_epoch_{current_epoch}.png'))\n",
                "    plt.close()\n",
                "\n",
                "def save_sample_predictions(model, loader, device, epoch, save_path, num_samples=3):\n",
                "    \"\"\"Saves 3-panel sample predictions (Image, Ground Truth, Prediction).\"\"\"\n",
                "    model.eval()\n",
                "    try:\n",
                "        images, masks, _ = next(iter(loader))\n",
                "        images = images.to(device)\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            logits = model(images)\n",
                "            probs = torch.sigmoid(logits)\n",
                "            preds = (probs > 0.5).float()\n",
                "        \n",
                "        images = images.cpu()\n",
                "        masks = masks.cpu()\n",
                "        preds = preds.cpu()\n",
                "        \n",
                "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
                "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
                "        \n",
                "        for i in range(min(num_samples, len(images))):\n",
                "            img = (images[i] * std) + mean\n",
                "            img = to_pil_image(img.clamp(0, 1))\n",
                "            gt_mask = to_pil_image(masks[i].squeeze(0))\n",
                "            pred_mask = to_pil_image(preds[i].squeeze(0))\n",
                "            \n",
                "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
                "            ax1.imshow(img)\n",
                "            ax1.set_title(\"Image\")\n",
                "            ax1.axis('off')\n",
                "            ax2.imshow(gt_mask, cmap='gray')\n",
                "            ax2.set_title(\"Ground Truth\")\n",
                "            ax2.axis('off')\n",
                "            ax3.imshow(pred_mask, cmap='gray')\n",
                "            ax3.set_title(\"Prediction\")\n",
                "            ax3.axis('off')\n",
                "            \n",
                "            plt.suptitle(f'Epoch {epoch} Sample {i+1}')\n",
                "            plt.savefig(os.path.join(save_path, f'epoch_{epoch}_sample_{i+1}.png'))\n",
                "            plt.close()\n",
                "    except Exception as e:\n",
                "        print(f\"Error plotting samples: {e}\")\n",
                "    finally:\n",
                "        model.train()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 9. Training Loop ---\n",
                "\n",
                "model = SwinUNet(num_classes=1).to(DEVICE)\n",
                "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
                "criterion = combined_loss\n",
                "\n",
                "train_losses = []\n",
                "val_losses = []\n",
                "train_mious = []\n",
                "val_mious = []\n",
                "labeled_pool_sizes = []\n",
                "new_labels_per_epoch = []\n",
                "\n",
                "best_miou = 0.0\n",
                "\n",
                "for epoch in range(START_EPOCH, NUM_EPOCHS + 1):\n",
                "    print(f\"\\n=== Epoch {epoch}/{NUM_EPOCHS} ===\")\n",
                "    \n",
                "    # --- 1. Prepare Training Data ---\n",
                "    current_labeled_files = labeled_pool_files + list(pseudo_masks.keys())\n",
                "    current_dataset = PolypDataset(\n",
                "        current_labeled_files,\n",
                "        IMAGE_DIR,\n",
                "        MASK_DIR,\n",
                "        pseudo_masks=pseudo_masks\n",
                "    )\n",
                "    \n",
                "    train_loader = DataLoader(\n",
                "        current_dataset,\n",
                "        batch_size=BATCH_SIZE,\n",
                "        shuffle=True,\n",
                "        num_workers=2\n",
                "    )\n",
                "    \n",
                "    # --- 2. Train ---\n",
                "    model.train()\n",
                "    epoch_loss = 0\n",
                "    epoch_iou = 0\n",
                "    iterations = 0\n",
                "    \n",
                "    pbar = tqdm(total=ITERATIONS_PER_EPOCH, desc=\"Training\")\n",
                "    train_iter = iter(train_loader)\n",
                "    \n",
                "    while iterations < ITERATIONS_PER_EPOCH:\n",
                "        try:\n",
                "            images, masks, _ = next(train_iter)\n",
                "        except StopIteration:\n",
                "            train_iter = iter(train_loader)\n",
                "            images, masks, _ = next(train_iter)\n",
                "            \n",
                "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        logits = model(images)\n",
                "        loss = criterion(logits, masks)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        # Calculate Training Metric for this batch\n",
                "        iou_batch, _ = calculate_metrics(logits, masks)\n",
                "        epoch_loss += loss.item()\n",
                "        epoch_iou += iou_batch\n",
                "        \n",
                "        iterations += 1\n",
                "        pbar.update(1)\n",
                "        \n",
                "    pbar.close()\n",
                "    avg_train_loss = epoch_loss / ITERATIONS_PER_EPOCH\n",
                "    avg_train_iou = epoch_iou / ITERATIONS_PER_EPOCH\n",
                "    train_losses.append(avg_train_loss)\n",
                "    train_mious.append(avg_train_iou)\n",
                "    labeled_pool_sizes.append(len(current_labeled_files))\n",
                "    \n",
                "    # --- 3. Validate ---\n",
                "    model.eval()\n",
                "    val_loss = 0\n",
                "    val_miou = 0\n",
                "    with torch.no_grad():\n",
                "        for images, masks, _ in val_loader:\n",
                "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
                "            logits = model(images)\n",
                "            val_loss += criterion(logits, masks).item()\n",
                "            iou, _ = calculate_metrics(logits, masks)\n",
                "            val_miou += iou\n",
                "            \n",
                "    avg_val_loss = val_loss / len(val_loader)\n",
                "    avg_val_miou = val_miou / len(val_loader)\n",
                "    val_losses.append(avg_val_loss)\n",
                "    val_mious.append(avg_val_miou)\n",
                "    \n",
                "    print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val mIoU: {avg_val_miou:.4f}\")\n",
                "    \n",
                "    # --- 4. Pseudo-Labeling (Semi-Supervised Only) ---\n",
                "    new_pseudos_this_epoch = 0\n",
                "    if TRAINING_SIZE < 490 and (epoch % 1 == 0):\n",
                "        print(\"Generating pseudo-labels...\")\n",
                "        model.eval()\n",
                "        \n",
                "        # Create loader for unlabeled pool\n",
                "        if unlabeled_pool_files:\n",
                "            unlabeled_dataset = PolypDataset(unlabeled_pool_files, IMAGE_DIR, MASK_DIR)\n",
                "            unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
                "            \n",
                "            width_candidates = []\n",
                "            \n",
                "            with torch.no_grad():\n",
                "                for images, _, filenames in unlabeled_loader:\n",
                "                    images = images.to(DEVICE)\n",
                "                    logits = model(images)\n",
                "                    probs = torch.sigmoid(logits)\n",
                "                    preds = (probs > 0.5).float()\n",
                "                    \n",
                "                    # Evaluate confidence\n",
                "                    for i in range(len(images)):\n",
                "                        fname = filenames[i]\n",
                "                        prob_map = probs[i].squeeze(0)\n",
                "                        pred_mask = preds[i].squeeze(0)\n",
                "                        \n",
                "                        conf = get_confidence_score(prob_map, pred_mask)\n",
                "                        \n",
                "                        if conf > CONFIDENCE_THRESHOLD:\n",
                "                            pseudo_masks[fname] = pred_mask.cpu().numpy()\n",
                "                            width_candidates.append(fname)\n",
                "                            new_pseudos_this_epoch += 1\n",
                "            \n",
                "            # Update pools\n",
                "            for fname in width_candidates:\n",
                "                if fname in unlabeled_pool_files:\n",
                "                    unlabeled_pool_files.remove(fname)\n",
                "            \n",
                "            print(f\"Added {new_pseudos_this_epoch} new pseudo-labels. Total Pseudo: {len(pseudo_masks)}\")\n",
                "    \n",
                "    new_labels_per_epoch.append(new_pseudos_this_epoch)\n",
                "            \n",
                "    # --- 5. Save Checkpoints & Plots ---\n",
                "    torch.save({\n",
                "        'epoch': epoch,\n",
                "        'model_state_dict': model.state_dict(),\n",
                "        'optimizer_state_dict': optimizer.state_dict(),\n",
                "        'train_losses': train_losses,\n",
                "        'val_losses': val_losses,\n",
                "        'train_mious': train_mious,\n",
                "        'val_mious': val_mious,\n",
                "    }, LATEST_MODEL_PATH)\n",
                "    \n",
                "    # Save Best Model\n",
                "    if avg_val_miou > best_miou:\n",
                "        best_miou = avg_val_miou\n",
                "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
                "        print(f\"New Best Model Saved! (mIoU: {best_miou:.4f})\")\n",
                "    \n",
                "    # Call Visualization Functions\n",
                "    save_sample_predictions(model, val_loader, DEVICE, epoch, PLOT_PATH)\n",
                "    save_loss_metric_plots(train_losses, val_losses, train_mious, val_mious, epoch, PLOT_PATH)\n",
                "    if TRAINING_SIZE < 490:\n",
                "        save_data_growth_plot(labeled_pool_sizes, epoch, PLOT_PATH)\n",
                "        save_new_labels_plot(new_labels_per_epoch, epoch, PLOT_PATH)\n",
                "        \n",
                "    print(f\"Mode and Plots saved to {RUN_PATH}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}